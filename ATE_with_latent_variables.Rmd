---
title: "Estimating average treatment effect with latent variables"
author: "Iyar Lin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, cache = F)
set.seed(2)
options(scipen = 999)

packages <- c(
  "devtools", # install_github
  "tidyverse", # best thing that happend to me
  "pander",  # table rendering
  "dagitty", # plot dags
  "ggdag", # ggplto dags
  "np" # npcdens etc
)

sapply(
  packages,
  function(x) if (!require(x, character.only = TRUE, quietly = T)) {
      install.packages(x, quiet = T, verbose = F)
      library(x, character.only = T, quietly = T, verbose = F)
    }
)
```

# Intro  
In some cases the backdoor criteria might indicate we need to condition on an unmeasured (latent) variable. Often times we'll have proxy variables (i.e. noisy measurments of the latent variable) at hand. In this script I demonstrate use cases where those proxy variables can be used to estimate the ATE (for details about the theory and background see "M. Kuroki and J. Pearl. Measurement bias and effect restoration in causal inference. Technical report,
DTIC Document, 2011.")

# Define model graph

We consider the following grpahical model:


```{r plot model graph}
g <- dagify(Y ~ U + X,
            X ~ U, 
            W ~ U, 
            Z ~ U, 
            coords = data.frame(name = c("Z", "U", "X", "W", "Y"), 
                                x = c(-1, 0, 1, 2, 3), 
                                y = c(0, 1, 0, 1, 0)), 
            exposure = "X", 
            outcome = "Y")

ggdag(tidy_dagitty(g))
```

# 1) When $p(w|u)$ is known

We'll ignore $Z$ in this example.

Under the following conditions the ATE can be estimated:

1. The distribution $p(w|u)$ is known
1. $W$ and the confounder $U$ are discrete variables with a given finite number of categories $k$

We thus assume the following toy model with $k=3$ and the levels $\{w_1, w_2, w_3\}$ and $\{u_1, u_2, u_3\}$:

$$
U \in \{a, b, c\}, \, W \in \{a, b, c\}
$$

and the conditional probabilities $p(w|u)$ are given by the following matrix:

$$
M(w,u) = \left(\begin{matrix} 0.2 & 0.1 & 0.7 \\ 0.3 & 0.8 & 0.1 \\ 0.5 & 0.1 & 0.2 \end{matrix}\right)
$$

where $M_{1,2}=p(W=a|U=b)=0.3$ etc. 

We also assume:

$$
Y = 0.2X + 0.5I_{\{U=a\}} - 0.1I_{\{U=b\}} - 0.5I_{\{U=c\}} + \epsilon
$$
$$
p(U=a)=0.5, \, p(U=b)=0.1, \, p(U=c)=0.4
$$
$$
X = -0.5I_{\{U=a\}} + 0.1I_{\{U=b\}} + 0.5I_{\{U=c\}} + \epsilon
$$

Below I simulate the dataset:

```{r}
N <- 10000
U <- sample(x = c("a", "b", "c"), size = N, replace = T, prob = c(0.5, 0.1, 0.4))
X <- rnorm(N) + case_when(U == "a" ~ -0.5, U == "b" ~ 0.1, U == "c" ~ 0.5)
Y <- 0.4*X + case_when(U == "a" ~ 0.5, U == "b" ~ -0.1, U == "c" ~ -0.5) + rnorm(N)
M <- matrix(c(0.2, 0.1, 0.7, 
              0.3, 0.8, 0.1, 
              0.5, 0.1, 0.2), 
            byrow = T, ncol = 3)

W <- vector(length = length(U))
W[U == "a"] <- sample(c("a", "b", "c"), size = sum(U =="a"), replace = T, prob = c(M[1,1], M[2,1], M[3,1]))
W[U == "b"] <- sample(c("a", "b", "c"), size = sum(U =="b"), replace = T, prob = c(M[1,2], M[2,2], M[3,2]))
W[U == "c"] <- sample(c("a", "b", "c"), size = sum( U=="c"), replace = T, prob = c(M[1,3], M[2,3], M[3,3]))

sim_data <- data.frame(X, Y, W, U)
```

The ATE in our case is 

$$
\mathbb{E}(Y|do(X=1)) = 0.2 + 0.4\cdot 0.3 - 0.2 \cdot 0.2 + 0.3 \cdot 0.5 = 0.43
$$

The estimator for the ATE is:

$$
\mathbb{E}(Y|do(x)) = \sum_y y\sum_{l=1}^{k}\frac{\sum_{j=1}^{k}i(w_j, u_l)p(y,w_j|x)\sum_{j=1}^{k}i(w_j,u_l)p(w_j)}{\sum_{j=1}^{k}i(w_j, u_l)p(w_j|x)}
$$

```{r}
M_inv <- solve(M)
p_w <- table(sim_data$W)/nrow(sim_data)

bw <- npcdens(W ~ X, data = sim_data[1:1000,])$bws
p_w_given_x_f <- npcdens(bws = bw, data = sim_data)
bw <- npcdens(Y + W ~ X, data = sim_data[1:1000,])$bws
p_y_w_given_x_f <- npcdens(bws = bw, data = sim_data)


Y_model <- lm(Y ~ W + X, data = sim_data)

p_y_given_do_x_times_y <- function(y, x){
  ans <- 0
  p_y_w_given_x <- predict(p_y_w_given_x_f, 
                           newdata = data.frame(W = factor(levels(sim_data$W), levels = levels(sim_data$W)), 
                                                Y = y,
                                                X = x))
  p_w_given_x <- predict(p_w_given_x_f, 
                         newdata = data.frame(W = factor(levels(sim_data$W), levels = levels(sim_data$W)),
                                                X = x))
  for(l in 1:ncol(M_inv)){
    p_y_u_given_x <- t(M_inv[, l]) %*% p_y_w_given_x
    p_u <- t(M_inv[, l]) %*% p_w
    p_u_give_x <- t(M_inv[, l]) %*% p_w_given_x
    ans <- ans + p_y_u_given_x*p_u/p_u_give_x
  }
  
  return(y*ans)
}

X_range <- seq(quantile(sim_data$X, 0.25), quantile(sim_data$X, 0.75), length.out = 10)
ATE_vec <- vector(length = length(X_range)); naive_ATE_vec <- vector(length = length(X_range))
width <- 0.1
Y_range <- seq(min(sim_data$Y), max(sim_data$Y), by = width)

for(i in 1:length(X_range)){
  ATE_vec[i] <- sum(sapply(Y_range, function(y){
    p_y_given_do_x_times_y(y,X_range[i])*width
  }))
  naive_ATE_vec[i] <- mean(predict(Y_model, sim_data %>% mutate(X=X_range[i])))
}



truth <- X_range*0.4 + 0.04

data.frame(val = c(ATE_vec, naive_ATE_vec, truth), x = rep(X_range, 3), model = rep(c("corrected", "naive", "truth"), each = length(ATE_vec))) %>% 
  ggplot(aes(x, val, color = model)) + geom_line()
```


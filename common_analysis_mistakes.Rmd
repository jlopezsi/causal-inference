---
title: "Common analysis mistakes (Or: why we've been doing it wrong all along"
author: "Iyar Lin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document:
    toc: true
    toc_depth: 2
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, warning = F, message = F, cache = F)
set.seed(1)
options(scipen = 999)

packages <- c(
  "devtools", # install_github
  "tidyverse", # best thing that happend to me
  "pander" # table rendering
)

sapply(
  packages,
  function(x) if (!require(x, character.only = TRUE, quietly = T)) {
      install.packages(x, quiet = T, verbose = F)
      library(x, character.only = T, quietly = T, verbose = F)
    }
)

if (!require(dagitty)) {
  install_github("jtextor/dagitty/r") # Analysis of structural causal models
  library(dagitty, quietly = T)
}
```

# Intro
When trying to estimate the impact of some decisions several methods are usually utilized, all of which are flawed and produce biased estimates.

# Common analysis strategies

## Looking on bi-variate relationship

Let's assume we measure the following variables:

* revenue: Overall sales revenue for a given year
* RD: How much we spent on Reaserach and Development in the previous year
* MS: Relative share of the market for a given year

Let's also assume that the graph below depicts the causal relationships between the above variables:

```{r define model1 and plot}
g <- dagitty("dag {
revenue [outcome]
RD [exposure]
RD -> revenue [beta = 0.15]
MS -> RD [beta = -0.4]
MS -> revenue [beta = 0.9]
}")

plot(graphLayout(g))

N <- 100000
```


We'll also assume that the relationships are linear with the following coefficients:

$\beta_{RD\rightarrow revenue} = 0.15$
$\beta_{MS\rightarrow RD} = -0.4$
$\beta_{MS\rightarrow revenue} = 0.9$

The effect of increasing RD on revenue $\delta \text{revenue} / \delta \text{RD}$ is:

$$\delta \text{revenue} / \delta \text{RD} = \beta_{RD\rightarrow revenue} = 0.15$$

Below I simulate a dataset from the above graph with `r N` observations

```{r simulate dataset1}
sim_data <- simulateSEM(g, N = N, standardized = T)
```

If we were to plot the relation between RD and revenue we would get:

```{r plot bi-variate relation}
sim_data %>%
  ggplot(aes(RD, revenue)) +
  geom_point(alpha = 0.05) + geom_smooth(method = "lm")
```

Fitting the linear model:

$$revenue = \beta_1RD + \epsilon$$

```{r fit model1}
model <- lm(revenue ~ RD, data = sim_data)
```

We get the following coefficients:

```{r model coefficients1, results = "asis"}
pandoc.table(coefficients(model))
```

We get the opposite relationship than what we'd expect!

## "Controlling" for as many variables as possible

Notionally we know that may arise due to MS being a confounding variable. Often times we fix confounding variables by "controlling" for as many things we can.

Let's assume we also measure:  

* CS: Customer satisifaction

We'll assume the graph below depicts the causal relationships between the all measured variables:

```{r define model 2}
g <- dagitty("dag {
revenue [outcome]
RD [exposure]
RD -> CS [beta = 0.3]
CS -> revenue [beta = 0.5]
MS -> RD [beta = -0.4]
MS -> revenue [beta = 0.9]
}")

plot(graphLayout(g))
```

We'll also assume that the relationships are linear with the following coefficients:

$\beta_{RD\rightarrow CS} = 0.3$
$\beta_{CS\rightarrow revenue} = 0.5$
$\beta_{MS\rightarrow RD} = -0.4$
$\beta_{MS\rightarrow revenue} = 0.9$

The effect of increasing RD on revenue $\delta \text{revenue} / \delta \text{RD}$ in this case is:

$$\delta \text{revenue} / \delta \text{RD} = \beta_{RD\rightarrow CS} \cdot \beta_{CS\rightarrow revenue} = 0.15$$

If we fit a regression using all variables available:

$$revenue = \beta_1RD + \beta_2MS + \beta_3CS + \epsilon$$

We'll obtain the following coefficient estimates:

```{r fit model2, results = "asis"}
sim_data <- simulateSEM(g, N = N, standardized = T)
model <- lm(revenue ~ ., data = sim_data)
pandoc.table(coefficients(model))
```

We can see that the coefficient of RD is about 0. This happens because conditioning on CS blocks the path from RD to revenue.

If we instead fit the model:

$$revenue = \beta_1RD + \beta_2MS + \epsilon$$

```{r fit model22}
model <- lm(revenue ~ RD + MS, data = sim_data)
```

We get the following coefficients:

```{r model coefficients2, results = "asis"}
pandoc.table(coefficients(model))
```

Obtaining the true RD effect.

# Using DAGs is the solution

Next let's assume we also measure:  

* population: How many potential customers in the market 
* demo: Demographics (rich population, dense population etc)  

We'll assume the graph below depicts the causal relationships between the all measured variables:

```{r define model 3}
g <- dagitty("dag {
revenue [outcome]
RD [exposure]
RD -> CS [beta = 0.3]
CS -> revenue [beta = 0.5]
MS -> RD [beta = -0.4]
MS -> revenue [beta = 0.9]
population -> MS [beta = -0.5]
population -> RD [beta = 0.7]
demo -> MS [beta = 0.3]
demo -> revenue [beta = 0.2]
}")

plot(graphLayout(g))
```

This time around neither conditioning on MS: 

```{r fit model3, results = "asis"}
sim_data <- simulateSEM(g, N = N, standardized = T)
model <- lm(revenue ~ RD + MS, data = sim_data)
pandoc.table(coefficients(model))
```

neither using all variables will help us: 

```{r fit model33, results = "asis"}
sim_data <- simulateSEM(g, N = N, standardized = T)
model <- lm(revenue ~ ., data = sim_data)
pandoc.table(coefficients(model))
```

We'll have to use graphical model math (backdoor criteria in this case) to discover that we need to condition on: 

```{r adjustment sets}
print(adjustmentSets(g))
```

So running the model:

$$revenue = \beta_1RD + \beta_2MS + \beta_3 demo + \epsilon$$

```{r fit model333}
sim_data <- simulateSEM(g, N = N, standardized = T)
model <- lm(revenue ~ RD + MS + demo, data = sim_data)
```

We get the following coefficients:

```{r model coefficients3, results = "asis"}
pandoc.table(coefficients(model))
```

Obtaining the true RD effect.

